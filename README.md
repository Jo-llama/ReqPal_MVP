# ReqPal RAG MVP

A **lightweight MVP** to test RAG (Retrieval-Augmented Generation) features.

## ğŸ¯ What This Is

- Enhanced project creation with rich metadata
- Document upload (PDF, DOCX, CSV, TXT, JSON)
- Automatic text extraction, chunking, and embedding
- Semantic search across documents
- 100% local embeddings (no API costs!)

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Start Server

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8001
```

**Note:** Port 8001 so it doesn't conflict with your main ReqPal on 8000!

### 3. Open Browser

```
http://localhost:8001/static/index.html
```

## ğŸ“ Project Structure

```
ReqPal-RAG-MVP/
â”œâ”€â”€ main.py                      # FastAPI app with RAG endpoints
â”œâ”€â”€ models.py                    # Data models (Project, Document, etc.)
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ reqpal_data.json            # Data storage (auto-created)
â”œâ”€â”€ __init__.py                  # Package initialization
â”œâ”€â”€ .env                         # Environment variables (not in repo)
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ rag_service.py           # RAG implementation
â”‚       â”œâ”€â”€ llm_router.py            # LLM provider routing
â”‚       â”œâ”€â”€ groq_http.py             # Groq API integration
â”‚       â”œâ”€â”€ reranker_service.py      # Result reranking
â”‚       â””â”€â”€ rag_llm_prompts.py       # Prompt templates
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html               # Web UI
â”‚
â”œâ”€â”€ uploads/                     # Uploaded documents (auto-created)
â”‚   â”œâ”€â”€ *.pdf                    # PDF documents
â”‚   â”œâ”€â”€ *.docx                   # Word documents
â”‚   â”œâ”€â”€ *.csv                    # CSV files
â”‚   â”œâ”€â”€ *.json                   # JSON files
â”‚   â””â”€â”€ *.bpmn                   # BPMN diagrams
â”‚
â””â”€â”€ storage/
    â””â”€â”€ chroma/                  # ChromaDB vector database (auto-created)
```

## ğŸ¯ Features

### 1. Enhanced Project Creation

Create projects with:
- Domain, industry, geography
- Regulatory exposure (GDPR, HIPAA, etc.)
- Success criteria
- Constraints (business, legal, technical)

### 2. Document Upload

Upload and automatically process:
- PDFs (text extraction)
- DOCX (paragraph extraction)
- CSV (structured data)
- TXT (plain text)
- JSON (structured data)

### 3. RAG Search

Semantic search across all documents:
- Natural language queries
- Filter by document type
- Similarity scoring
- Source attribution

**Fallback Options:**
- **Ollama**: Local LLM inference if API providers fail
- **Chunks-only mode**: Returns raw document chunks if LLM is unavailable

## ğŸ“Š Test It

1. **Create a project** with regulatory exposure
2. **Upload a PDF** (e.g., GDPR regulation)
3. **Search**: "What are data retention requirements?"
4. **See results** with similarity scores and source documents

## ğŸ”„ Merge Back to Main ReqPal

Once tested and working:
1. Copy successful features
2. Integrate endpoints
3. Update main UI
4. Deprecate this MVP

## ğŸ› Troubleshooting

**Model download fails:**

```bash
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
```

**Port already in use:**

Change port in command: `uvicorn main:app --port 8002`

**LLM API not working:**

The system will automatically fall back to:
1. **Ollama** (if installed locally): `ollama pull llama3.2`
2. **Chunks-only mode**: Returns relevant document snippets without LLM synthesis

